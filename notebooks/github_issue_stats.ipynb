{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1aba3f6-5531-4b0a-90f8-4200bd79edb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nwb_project_analytics.gitstats import NWBGitInfo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e916791b-5fd8-46be-ac20-de7b7b4521c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from github import Github, Label\n",
    "import pandas as pd\n",
    "from tqdm.notebook import tqdm\n",
    "from datetime import datetime\n",
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02b9e37b-021b-4ace-875a-85967f1a6950",
   "metadata": {},
   "source": [
    "# Configure inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01d7a712-b486-41fe-8eb9-8ad528aeee59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save results to\n",
    "output_dir = os.path.join(os.getcwd(), 'plots/') \n",
    "# save figures\n",
    "save_figs = True\n",
    "# exclude issues raised by core devs from response-time analysis\n",
    "DEV_USERNAMES = NWBGitInfo.CORE_DEVELOPERS \n",
    "# which repos to use. \n",
    "# Set to NWBGitInfo.CORE_API_REPOS to use only main API NWB repos. \n",
    "# Set to NWBGitInfo.GIT_REPOS to use all main NWB 2 repos\n",
    "REPOS =  NWBGitInfo.CORE_API_REPOS # NWBGitInfo.CORE_API_REPOS[0:1] #\n",
    "# Set datetime to filter issues older than START. E.g., set to  datetime(2021, 5, 1)\n",
    "START = datetime(2022, 1, 1) # NWBGitInfo.NWB1_DEPRECATION_DATE \n",
    "start_str = START.strftime(\"%Y-%m-%d\")\n",
    "end_str = datetime.now().strftime(\"%Y-%m-%d\")\n",
    "# threshold for long issues\n",
    "long_issue_threshold = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c803e12-42e2-48d3-aaa9-180c5e9d58d2",
   "metadata": {},
   "source": [
    "We need an API key from GitHub to access the API. See https://docs.github.com/en/github/authenticating-to-github/keeping-your-account-and-data-secure/creating-a-personal-access-token how to generate an access token.\n",
    "\n",
    "**WARNING:** Never check in a token to the repo\n",
    "**WARNING:** Only use tokens with read only access (never write access) to avoid accidental changes to the repo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23909843-ff57-4a48-86bd-603dcd68e957",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('ghk.txt', 'r') as f:\n",
    "    API_KEY = f.read().rstrip(\"\\n\")\n",
    "g = Github(API_KEY)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "192ee59c-91fa-4f7f-9f5f-c8033390d34f",
   "metadata": {},
   "source": [
    "# Retrieve all issues"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39502cb2-d08c-4a15-93b6-8c64001c4e3f",
   "metadata": {},
   "source": [
    "# Compile dataframe for issues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf112bbf-ded3-4dc6-ad17-fd68f2e99510",
   "metadata": {},
   "outputs": [],
   "source": [
    "issues_dfs = {repo: repo.get_issues_as_dataframe(since=START, github_obj=g, tqdm=tqdm)\n",
    "              for repo in tqdm(REPOS.values(), position=0, desc='repos')}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "064887b7-5459-45cd-a28c-c4fcd8e8f5f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the results to file\n",
    "for repo, issues in issues_dfs.items():\n",
    "    issues.to_csv(os.path.join(output_dir, \"issue_responses_%s.csv\") % repo.repo)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d27c34d-3d9b-4bfe-8afe-a9f4b2a86932",
   "metadata": {},
   "source": [
    "## Plot issue response times\n",
    "\n",
    "Issue response time in days is computed via the function ``GitRepo.compute_issue_time_of_first_response`` and is defined by the first event in the issue timeline where someone other than the creator of the issue either added a comment or label to the event or if the issue was closed. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9158e185-67cc-4db7-a6b8-dece4d76f63c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot stacked histogram plot for issues of all core repos\n",
    "response_time_data = []\n",
    "response_time_labels = []\n",
    "num_long_issues = []\n",
    "for repo, issues in issues_dfs.items():\n",
    "    # issue response times\n",
    "    response_times_for_new_issues = issues[issues['created_at'] > START]['days_to_response']\n",
    "    response_time_data.append(response_times_for_new_issues)\n",
    "    num_long_issues.append(np.sum(np.array(response_times_for_new_issues) > long_issue_threshold))\n",
    "    median_time = np.nanmedian(response_times_for_new_issues)\n",
    "    total_issues = len(response_times_for_new_issues)\n",
    "    label = \"%s \\n  * #issues=%i\\n  * median=%f days)\" % (repo.repo, total_issues, median_time)\n",
    "    response_time_labels.append(label)\n",
    "\n",
    "plt.figure(figsize=(8, 5))    \n",
    "plt.hist(response_time_data, \n",
    "         bins=np.max([np.max(response_time_data[i]) for i in range(len(response_time_data))]).astype(int),\n",
    "         label=response_time_labels,\n",
    "         density=False, \n",
    "         histtype='bar', \n",
    "         stacked=True)\n",
    "plt.xlabel(\"Initial response time in days\")\n",
    "plt.ylabel(\"#Issues\")\n",
    "plt.legend()\n",
    "plt.xlim((0, long_issue_threshold))\n",
    "plt.title(\"Issue response time: %s - %s\" % (start_str, end_str))\n",
    "\n",
    "if save_figs:\n",
    "    plt.savefig(os.path.join(output_dir, 'NWB_ALL_issue_response_times_%s_%s.pdf' % (start_str, end_str)))\n",
    "    plt.savefig(os.path.join(output_dir, 'NWB_ALL_issue_response_times_%s_%s.png' % (start_str, end_str)))\n",
    "plt.show()\n",
    "\n",
    "print(\"#Issue with response time > %i days\" % long_issue_threshold)\n",
    "for i, n in enumerate(num_long_issues):\n",
    "    print(\"%s: %i\" % (response_time_labels[i].split(\"\\n\")[0], n))\n",
    "total_num_issues = np.sum([len(rtd) for rtd in response_time_data])\n",
    "total_long_issues = np.sum(num_long_issues)\n",
    "print(\"Total issues: %i\" % total_num_issues)\n",
    "print(\"Total long issues: %i\" % total_long_issues)\n",
    "print(\"Percent long issues: %f\" % (float(total_long_issues)/float(total_num_issues) * 100)   )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9497fb26-c4f1-4667-a914-1820b8059ecb",
   "metadata": {},
   "source": [
    "## Show issues with long estimated response times that were created after the START date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27e9a98c-ea6f-4359-b742-a580aa84a070",
   "metadata": {},
   "outputs": [],
   "source": [
    "for repo, issues in issues_dfs.items():\n",
    "    long_issues = issues[(issues['created_at'] > START) & (issues['days_to_response'] > long_issue_threshold)]\n",
    "    print(repo.repo, len(long_issues))\n",
    "    display(long_issues)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d042bc6-fc60-4a15-9652-bdac9d1dc1a2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "855f608f-949e-475f-b1f7-5865bb61b59d",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f649d1c-47e3-457d-88b2-98d2ae6fc029",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36759999-d594-44dd-8170-e594494e0141",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "84472655-2808-4da0-ab78-0aa28029c25f",
   "metadata": {},
   "source": [
    "## Issue summary plots for the individual repositories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94ca6d8d-acb7-4f5a-9dc5-caf05bc5ab9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "for repo, issues in issues_dfs.items():\n",
    "    for k in ['updated_at', 'created_at', 'closed_at']:\n",
    "        issues.groupby([issues[k].dt.year , issues[k].dt.month])[k].count().plot(kind=\"bar\", figsize=(8,4))\n",
    "        plt.show()\n",
    "    \n",
    "    # issue response times\n",
    "    response_times_for_new_issues = issues[issues['created_at'] > START]['days_to_response']\n",
    "    plt.hist(response_times_for_new_issues, bins=np.ceil(np.max(response_times_for_new_issues)).astype('int'))\n",
    "    #plt.xlim((0,10))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "118aeb55-1306-42ba-99ca-d28042acc4de",
   "metadata": {},
   "source": [
    "## Median Response time analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77bcb24b-68c7-45aa-9133-6784dd77ec92",
   "metadata": {},
   "outputs": [],
   "source": [
    "for repo, idf in issues_dfs.items():\n",
    "    # Exclude enhancements and help wanted issues. Also exclude issues by core developers and issues that were orignially created after START\n",
    "    query = ~idf.is_enhancement & ~idf.is_help_wanted & ~idf.user_login.isin(DEV_USERNAMES) & (idf.created_at >= START)\n",
    "    res = idf[query]\n",
    "    print(repo)\n",
    "    display(res)\n",
    "    if len(res) > 0:\n",
    "        #try:\n",
    "        res.hist(column='days_to_response')\n",
    "        plt.title(repo.repo)\n",
    "        plt.xlabel(\"Days to response\")\n",
    "        plt.ylabel(\"Count\")\n",
    "        plt.show()\n",
    "        #except:\n",
    "        #    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a1c1d49-e7ab-4768-bb1a-22d02a27195a",
   "metadata": {},
   "source": [
    "# Unresponded issues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e3ae989-37d9-406a-8006-06fe33eabdcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "for repo, idf in issues_dfs.items():\n",
    "    query = pd.isna(idf.response_time)\n",
    "    res = idf[query]\n",
    "    print(repo)\n",
    "    display(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78d446d3-0bc9-423a-bf1c-0b00f230a92a",
   "metadata": {},
   "source": [
    "# Issues by label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ff1e56b-1d15-471a-95d5-07867510078c",
   "metadata": {},
   "outputs": [],
   "source": [
    "fontsize = 16\n",
    "save_figs = True\n",
    "curr_date = datetime.now().strftime(\"%Y-%m-%d\")\n",
    "num_issues = {standard_label.label: [] for standard_label in NWBGitInfo.STANDARD_ISSUE_LABELS.values()}\n",
    "num_issues['No labels'] = []\n",
    "num_issues['Custom labels'] = []\n",
    "for repo, idf in issues_dfs.items():\n",
    "    # Compute counts for standard issues\n",
    "    for standard_label in NWBGitInfo.STANDARD_ISSUE_LABELS.values():\n",
    "        # Compute a binary vector indicating which issues have the given label \n",
    "        rows = idf.labels.apply(lambda x: standard_label.label in [l.name for l in x])\n",
    "        num_issues[standard_label.label].append(np.sum(rows))\n",
    "    # Compute count of issues with no label\n",
    "    rows = idf.labels.apply(lambda x: len(x) == 0)\n",
    "    num_issues['No labels'].append(np.sum(rows))\n",
    "    # Compute count of issues with non-standard labels\n",
    "   \n",
    "    def contains_nonstandard_label(labels):\n",
    "        standard_labels = [standard_label.label for standard_label in NWBGitInfo.STANDARD_ISSUE_LABELS.values()] + ['help wanted: good first issue']\n",
    "        for label in labels:\n",
    "            if label.name not in standard_labels and not label.name.startswith('topic: '):\n",
    "                return True\n",
    "        return False\n",
    "    rows = idf.labels.apply(contains_nonstandard_label)\n",
    "    num_issues['Custom labels'].append(np.sum(rows))\n",
    "num_issues_df = pd.DataFrame.from_dict(num_issues)\n",
    "num_issues_df.index = [\"%s (%i)\" % (repo.repo, len(idf)) for repo, idf in issues_dfs.items()]\n",
    "num_issues_df.transpose().plot.barh(stacked=True, figsize=(14,10), fontsize=fontsize, rot=0)\n",
    "plt.xlabel(\"Number of Issues (incl. PRs)\", fontsize=fontsize)\n",
    "plt.ylabel(\"Issue label\", fontsize=fontsize)\n",
    "plt.legend(fontsize=fontsize, loc='lower right')\n",
    "plt.title(\"Number of issues per standard label (%s)\" % curr_date, fontsize=fontsize)\n",
    "plt.tight_layout()\n",
    "if save_figs:\n",
    "    plt.savefig(os.path.join(output_dir, 'nwb_issues_by_label_%s.pdf' % curr_date))\n",
    "    plt.savefig(os.path.join(output_dir, 'nwb_issues_by_label_%s.png' % curr_date))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0a476e8-232f-47c7-a9e8-d13fe2a55f96",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "486a1474-af48-4026-9b69-8c3296cf1f2f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b06282a-ca6a-4b3a-ace1-ed152fcfcd4c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9291319-88a5-442f-8e5e-75b7e3816dc8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
